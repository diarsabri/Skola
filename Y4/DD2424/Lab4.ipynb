{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DD2424 Deep Learning in Data Science - Lab 4\r\n",
    "\r\n",
    "## Diar Sabri - July 2021"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# imports\r\n",
    "import numpy as np\r\n",
    "import pickle\r\n",
    "import decimal\r\n",
    "from google.colab import drive\r\n",
    "drive.mount('/content/drive')\r\n",
    "import copy\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import math"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bdtln6S8PbgT",
    "outputId": "1f36aa69-32ab-4b9b-ccb8-3b7d84fa8319"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "text = open('/content/drive/MyDrive/Colab Notebooks/goblet-of-fire/goblet_book.txt', 'r', encoding='utf8').read()\r\n",
    "chars = list(set(text))\r\n",
    "char_to_ind = {\r\n",
    "    char: i for i, char in enumerate(chars)\r\n",
    "}\r\n",
    "ind_to_char = {\r\n",
    "    idx: char for idx, char in enumerate(chars)\r\n",
    "}\r\n",
    "\r\n",
    "onehot = np.zeros((len(chars), len(text)))\r\n",
    "for i, chr in enumerate(text):\r\n",
    "  label = char_to_ind[chr]\r\n",
    "  onehot[label, i] = 1\r\n",
    "\r\n",
    "all_X = onehot\r\n",
    "all_Y = np.roll(all_X, -1, axis=1)"
   ],
   "outputs": [],
   "metadata": {
    "id": "7oID-Z8kQufm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def InitalizeLayers(K, m=100, sig=0.01):\r\n",
    "  NetParams = {\r\n",
    "    'b': np.zeros((m, 1)),\r\n",
    "    'c': np.zeros((K, 1)),\r\n",
    "    'U': np.random.normal(0, sig, size=(m, K)),\r\n",
    "    'W': np.random.normal(0, sig, size=(m, m)),\r\n",
    "    'V': np.random.normal(0, sig, size=(K, m)),\r\n",
    "    'm': m,\r\n",
    "    'K': K,\r\n",
    "  }\r\n",
    "\r\n",
    "  return NetParams"
   ],
   "outputs": [],
   "metadata": {
    "id": "RvKa4U2coXq_"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def ForwardPass(X, h0, NetParams):\r\n",
    "  n = X.shape[1]\r\n",
    "  a, h, o, P = [], [h0], [], []\r\n",
    "  for t in range(n):\r\n",
    "    a.append((NetParams['W'] @ h[t] + NetParams['U'] @ X[:, [t]] + NetParams['b']))\r\n",
    "    h.append(np.tanh(a[t]))\r\n",
    "    o.append((NetParams['V'] @ h[t+1] + NetParams['c']))\r\n",
    "    P.append(np.exp(o[t]) / np.sum(np.exp(o[t]), axis=0)) #sm\r\n",
    "\r\n",
    "  RNNParams = {\r\n",
    "      'a': np.squeeze(np.asarray(a)).T,\r\n",
    "      'h': np.squeeze(np.asarray(h)).T,\r\n",
    "      'o': np.squeeze(np.asarray(o)).T,\r\n",
    "      'P': np.squeeze(np.asarray(P)).T,\r\n",
    "  }\r\n",
    "\r\n",
    "  return RNNParams"
   ],
   "outputs": [],
   "metadata": {
    "id": "I_27fCj0q-Ad"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def BackwardPass(X, Y, NetParams, RNNParams):\r\n",
    "  n = X.shape[1]\r\n",
    "  grad_o = -(Y - RNNParams['P']).T\r\n",
    "  grad_V = grad_o.T @ RNNParams['h'][:, 1:].T\r\n",
    "  \r\n",
    "  grad_h = [None for _ in range(n-1)] + [grad_o[-1] @ NetParams['V']]\r\n",
    "  grad_a = [None for _ in range(n-1)] + [grad_h[-1] @ np.diag(1 - np.square(np.tanh(RNNParams['a'][:, -1])))]\r\n",
    "  for t in reversed(range(n-1)):\r\n",
    "    grad_h[t] = grad_o[t] @ NetParams['V'] + grad_a[t+1] @ NetParams['W']\r\n",
    "    grad_a[t] = grad_h[t] @ np.diag(1 - np.square(np.tanh(RNNParams['a'][:, t])))\r\n",
    "\r\n",
    "  grad_W = np.asarray(grad_a).T @ RNNParams['h'][:, :-1].T\r\n",
    "  grad_U = np.asarray(grad_a).T @ X.T\r\n",
    "\r\n",
    "  grad_b = np.sum(grad_a, axis=0, keepdims=True).T\r\n",
    "  grad_c = np.sum(grad_o, axis=0, keepdims=True).T\r\n",
    "\r\n",
    "  grads = {\r\n",
    "    'b': grad_b,\r\n",
    "    'c': grad_c,\r\n",
    "    'U': grad_U,\r\n",
    "    'W': grad_W,\r\n",
    "    'V': grad_V,\r\n",
    "  }\r\n",
    "\r\n",
    "  for grad in grads:\r\n",
    "    grads[grad] = np.clip(grads[grad], -5, 5)\r\n",
    "\r\n",
    "  return grads"
   ],
   "outputs": [],
   "metadata": {
    "id": "goPMwMrGpEI2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def SynthesizeText(x0, h0, text_len, NetParams):\r\n",
    "  text = ''\r\n",
    "  hprev = h0\r\n",
    "  x = x0\r\n",
    "  for t in range(text_len):\r\n",
    "    RNNParams = ForwardPass(x, hprev, NetParams)\r\n",
    "    hprev = RNNParams['h'][:, [-1]]\r\n",
    "    ix = np.random.choice(range(NetParams['K']), p=RNNParams['P'].flat)\r\n",
    "    x = np.zeros((NetParams['K'], 1))\r\n",
    "    x[ix] = 1\r\n",
    "    char = ind_to_char[ix]\r\n",
    "\r\n",
    "    text += char\r\n",
    "  \r\n",
    "  return text"
   ],
   "outputs": [],
   "metadata": {
    "id": "RAIcoZH-Y_pJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def GenerateText():\r\n",
    "  text_len = 15\r\n",
    "  starting_char = ind_to_char[0]\r\n",
    "  print('Starting char: ' + starting_char)\r\n",
    "\r\n",
    "  K = len(ind_to_char)\r\n",
    "  NetParams = InitalizeLayers(K)\r\n",
    "  h0 = np.zeros((NetParams['m'], 1))\r\n",
    "  x0 = np.zeros((K, 1))\r\n",
    "  x0[0] = 1\r\n",
    "  return SynthesizeText(x0, h0, text_len, NetParams)"
   ],
   "outputs": [],
   "metadata": {
    "id": "9-lY0hsn-xPh"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "GenerateText()"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "IWj5mBgy-kdC",
    "outputId": "0f03bd6b-4ad2-4ad0-85f9-e737e7791855"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Gradients"
   ],
   "metadata": {
    "id": "bDIUwuVMYdxm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def ComputeGradsNumSlow(X, Y, NetParams, h):\r\n",
    "\r\n",
    "  grads = {\r\n",
    "      'b': np.zeros(NetParams['b'].shape),\r\n",
    "      'c': np.zeros(NetParams['c'].shape),\r\n",
    "      'U': np.zeros(NetParams['U'].shape),\r\n",
    "      'W': np.zeros(NetParams['W'].shape),\r\n",
    "      'V': np.zeros(NetParams['V'].shape),\r\n",
    "  }\r\n",
    "\r\n",
    "  h0 = np.zeros((NetParams['m'], 1))\r\n",
    "  for par in grads.keys():\r\n",
    "    for i in range(NetParams[par].size):\r\n",
    "      NetParams_try = copy.deepcopy(NetParams)\r\n",
    "      NetParams_try[par].flat[i] -= h\r\n",
    "      RNNParams_try = ForwardPass(X, h0, NetParams_try)\r\n",
    "      c1 = -np.sum(Y*np.log(RNNParams_try['P'])) #l\r\n",
    "      \r\n",
    "      NetParams_try = copy.deepcopy(NetParams)\r\n",
    "      NetParams_try[par].flat[i] += h\r\n",
    "      RNNParams_try = ForwardPass(X, h0, NetParams_try)\r\n",
    "      c2 = -np.sum(Y*np.log(RNNParams_try['P'])) #l\r\n",
    "      \r\n",
    "      grads[par].flat[i] = (c2 - c1) / (2*h)\r\n",
    "    \r\n",
    "  return grads"
   ],
   "outputs": [],
   "metadata": {
    "id": "FNBqC4rtYfuI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def CompareGradients():\r\n",
    "  h = 1e-4\r\n",
    "  tolerance = 1e-6\r\n",
    "\r\n",
    "  X, Y = all_X[:, :25], all_Y[:, :25]\r\n",
    "  K = len(ind_to_char)\r\n",
    "\r\n",
    "  NetParams = InitalizeLayers(K, m=5, seq_len=25, eta=0.1, sig=0.01)\r\n",
    "\r\n",
    "  h0 = np.zeros((NetParams['m'], 1))\r\n",
    "\r\n",
    "  RNNParams = ForwardPass(X, h0, NetParams)\r\n",
    "  loss = -np.sum(Y*np.log(RNNParams['P']))\r\n",
    "  grads = BackwardPass(X, Y, NetParams, RNNParams)\r\n",
    "\r\n",
    "  grads_num = ComputeGradsNumSlow(X, Y, NetParams, h)\r\n",
    "\r\n",
    "  for par in grads.keys():\r\n",
    "    equal = True\r\n",
    "    for i in range(grads[par].size):\r\n",
    "      elem = grads[par].flat[i]\r\n",
    "      elem_num = grads_num[par].flat[i]\r\n",
    "\r\n",
    "      diff = abs(elem - elem_num)\r\n",
    "      if diff >= tolerance:\r\n",
    "        print(par, elem, elem_num, diff)\r\n",
    "        equal = False\r\n",
    "    \r\n",
    "    print(par, equal)\r\n",
    "\r\n",
    "  return grads, grads_num"
   ],
   "outputs": [],
   "metadata": {
    "id": "Jf-gBmpHF4BW"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grads_a, grads_n = CompareGradients()"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJCOELaeIGX_",
    "outputId": "83f3f7d3-dd3a-40c6-c5c3-b63eca9c009b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train on Goblet of Fire "
   ],
   "metadata": {
    "id": "4IUDdr-Ms-n8"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def SGC(tra_X, tra_Y, GDP, NetParams):\r\n",
    "\r\n",
    "  mem = {\r\n",
    "      'b': np.zeros((NetParams['m'], 1)),\r\n",
    "      'c': np.zeros((NetParams['K'], 1)),\r\n",
    "      'U': np.zeros((NetParams['m'], NetParams['K'])),\r\n",
    "      'W': np.zeros((NetParams['m'], NetParams['m'])),\r\n",
    "      'V': np.zeros((NetParams['K'], NetParams['m'])),\r\n",
    "  }\r\n",
    "  smooth_loss = []\r\n",
    "  step = 0\r\n",
    "  for i in range(GDP['epochs']):\r\n",
    "    hprev = np.zeros((NetParams['m'], 1))\r\n",
    "    for j in range(tra_X.shape[1] // GDP['seq_len']):\r\n",
    "      X_batch = tra_X[:, j * GDP['seq_len'] : (j+1) * GDP['seq_len']]\r\n",
    "      Y_batch = tra_Y[:, j * GDP['seq_len'] : (j+1) * GDP['seq_len']]\r\n",
    "\r\n",
    "      RNNParams = ForwardPass(X_batch, hprev, NetParams)\r\n",
    "      h_prev = RNNParams['h'][:, [-1]]\r\n",
    "      grads = BackwardPass(X_batch, Y_batch, NetParams, RNNParams)\r\n",
    "\r\n",
    "      for par in grads.keys():\r\n",
    "        mem[par] += np.square(grads[par])\r\n",
    "        NetParams[par] -= GDP['eta'] * grads[par] / np.sqrt(mem[par] + np.finfo(float).eps)\r\n",
    "\r\n",
    "      loss = -np.sum(Y_batch*np.log(RNNParams['P']))\r\n",
    "      if step == 0:\r\n",
    "        smooth_loss.append((step, loss))\r\n",
    "      else:\r\n",
    "        smooth_loss.append((step, 0.999 * smooth_loss[-1][1] + 0.001 * loss))\r\n",
    "\r\n",
    "      if step % 1000 == 0: \r\n",
    "        print('Step ' + str(step) + ': ' + str(smooth_loss[-1]))\r\n",
    "\r\n",
    "      if step % 10000 == 0:\r\n",
    "        txt = SynthesizeText(X_batch[:, [0]], hprev, 200, NetParams)\r\n",
    "        print(txt)\r\n",
    "      \r\n",
    "      step += 1\r\n",
    "\r\n",
    "  return NetParams, smooth_loss"
   ],
   "outputs": [],
   "metadata": {
    "id": "3OufHFYKtYPd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def TrainGOF():\r\n",
    "  K = len(ind_to_char)\r\n",
    "  m = 100\r\n",
    "  sigma = 0.01\r\n",
    "  GDP = {\r\n",
    "      'eta': 0.1,\r\n",
    "      'epochs': 10,\r\n",
    "      'seq_len': 25,\r\n",
    "  }\r\n",
    "\r\n",
    "  NetParams = InitalizeLayers(K, m, sigma)\r\n",
    "  NetParams, loss = SGC(all_X, all_Y, GDP, NetParams)\r\n",
    "\r\n",
    "  # Syntesize a long text with the final settings\r\n",
    "  text_len = 1000\r\n",
    "  h0 = np.zeros((m, 1))\r\n",
    "  x0 = np.zeros((K, 1))\r\n",
    "  x0[0] = 1\r\n",
    "  txt = SynthesizeText(x0, h0, 1000, NetParams)\r\n",
    "\r\n",
    "  print('Best text: ' + txt)\r\n",
    "\r\n",
    "  return NetParams, loss, txt"
   ],
   "outputs": [],
   "metadata": {
    "id": "kU_jcCFTDyyi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def PlotLoss(loss):\r\n",
    "\r\n",
    "  tra_X = [x for x, y in loss]\r\n",
    "  tra_Y = [y for x, y in loss]\r\n",
    "\r\n",
    "  plt.plot(tra_X, tra_Y, label='Loss')\r\n",
    "  plt.legend()\r\n",
    "\r\n",
    "  plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "id": "7Hmq4PZTZBlu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "final_model, final_loss, final_txt = TrainGOF()\r\n",
    "PlotLoss(final_loss)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A1XJGTU7Ig36",
    "outputId": "552835e4-716c-46b9-c7d1-c54d32eadfd1"
   }
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}